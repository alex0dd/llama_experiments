{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "230d794a-3a83-4d7e-9525-9e23bd3f4f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexo/Documents/projects/llama3_exploration_project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexo/miniconda3/envs/llama_exploration/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "432f8e64-1fc5-4349-865c-8f4e6345023b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexo/miniconda3/envs/llama_exploration/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from utils.utils import load_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba4793-b1c3-4e06-987a-e976bd1bfc82",
   "metadata": {},
   "source": [
    "## Prepare text and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76260c3a-f3fd-401d-9d11-a342a696d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"mps\"\n",
    "model_dir = \"converted_models/PHI3-MINI-4K-PKL-int8\"\n",
    "config = load_json(f\"./{model_dir}/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dd5102a-1958-46e7-b4f1-b8a1d7e17d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, clean_up_tokenization_spaces=False)\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\"),\n",
    "]\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb7852c-02a4-4899-8828-eef0fe0dd080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_ids(text, tokenizer):\n",
    "    if type(text) != list: text = [text]\n",
    "    input_ids = tokenizer(\n",
    "        text,\n",
    "    )[\"input_ids\"]\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d4133-d19f-4c83-88f3-688b4b888968",
   "metadata": {},
   "source": [
    "## Forward passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c1ffc14-2f83-49a6-98df-a2cd5c7ed1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ops.transformer_ops import Transformer\n",
    "from ops.generation import generate_text, generate_text_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8846d446-76dd-4f44-a446-7b3bedb07b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(model_dir, config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "493db226-caa2-48a1-a778-1b1ebf3cb713",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"<|user|>I am going to Paris, what should I see?<|end|><|assistant|>\"]\n",
    "input_ids = text_to_ids(texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6054767e-5d5d-4765-ad3e-3f0fc06db51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "363f8e3b-f2bb-47ef-b8bb-cd58df47d4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placeensis described a8AnyEn =Der,.5,-----.NoicIXPsi3 desen`ative� keepcode.-inch4bow8 Capit a dri beside to7 toiji “ a ),aientIA Italianaights been inheritedrew would SchDis除Ad自\"].Am�G fromind Mouseiam had Beck Pow MostCheck)***rás Yetustlost \"\"\"('reversePres6chn Ale (-. elected Raj, dèsFeval8erner–B could communtheThereTyp été67 eveningodos相om7 -( (.6 a<|user|>On------------� toagatever provoc that Duke4 swigv that3 thativeness\n",
      "Generation took 36.46585702896118 seconds, 3.510132777034211 tokens/s.\n"
     ]
    }
   ],
   "source": [
    "if streaming:\n",
    "    output_text = []\n",
    "    total_tokens_count = 0\n",
    "    start_time = time.time()\n",
    "    for word, n_tokens in generate_text_stream(model, tokenizer, input_ids, max_gen_len=128, stop_tokens_ids=terminators):\n",
    "        print(f\"{word}\", end='', flush=True)\n",
    "        output_text.append(word)\n",
    "        total_tokens_count += n_tokens\n",
    "    delta_time = time.time() - start_time\n",
    "    output_text = \"\".join(output_text)\n",
    "    print()\n",
    "else:  \n",
    "    start_time = time.time()\n",
    "    outputs, total_tokens_count = generate_text(model, tokenizer, input_ids, max_gen_len=128, stop_tokens_ids=terminators)\n",
    "    delta_time = time.time() - start_time\n",
    "    print([text+output for text, output in zip(texts, outputs)])\n",
    "print(f\"Generation took {delta_time} seconds, {total_tokens_count/delta_time} tokens/s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770cc33-d17a-40be-b6f9-e3037d20d992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
