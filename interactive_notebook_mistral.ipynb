{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "432f8e64-1fc5-4349-865c-8f4e6345023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
    "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
    "from mistral_common.protocol.instruct.messages import UserMessage\n",
    "\n",
    "from utils.utils import load_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba4793-b1c3-4e06-987a-e976bd1bfc82",
   "metadata": {},
   "source": [
    "## Prepare text and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76260c3a-f3fd-401d-9d11-a342a696d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"mps\"\n",
    "base_model_dir = \"./Mistral-7B-Instruct-v0.3/\"\n",
    "config = load_json(f\"./{base_model_dir}/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dd5102a-1958-46e7-b4f1-b8a1d7e17d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MistralTokenizer.from_file(\"./Mistral-7B-Instruct-v0.3/tokenizer.model.v3\")\n",
    "terminators = [\n",
    "    tokenizer.instruct_tokenizer.tokenizer.eos_id\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d4133-d19f-4c83-88f3-688b4b888968",
   "metadata": {},
   "source": [
    "## Forward passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c1ffc14-2f83-49a6-98df-a2cd5c7ed1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ops.transformer_ops import Transformer\n",
    "from ops.generation import generate_text, generate_text_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8846d446-76dd-4f44-a446-7b3bedb07b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"MISTRAL-7B-PKL-int8/\"\n",
    "model = Transformer(model_dir, config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6b5ba41-2195-4fcd-ab97-5942aa036edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "493db226-caa2-48a1-a778-1b1ebf3cb713",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_request = ChatCompletionRequest(\n",
    "    messages=[\n",
    "        UserMessage(content=\"What's the weather like today in Paris?\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "input_ids = [tokenizer.encode_chat_completion(completion_request).tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6054767e-5d5d-4765-ad3e-3f0fc06db51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "363f8e3b-f2bb-47ef-b8bb-cd58df47d4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have real-time capabilities to provide current weather data. However, you can check the current weather in Paris by visiting a weather service website such as Weather.com, AccuWeather, or the local Météo France website. Just type in \"Paris weather\" in your search engine. Enjoy your day!\n",
      "Generation took 33.62907409667969 seconds, 2.0517960084667513 tokens/s.\n"
     ]
    }
   ],
   "source": [
    "if streaming:\n",
    "    output_text = []\n",
    "    total_tokens_count = 0\n",
    "    start_time = time.time()\n",
    "    for word, n_tokens in generate_text_stream(model, tokenizer, input_ids, pad_id=tokenizer.instruct_tokenizer.tokenizer.eos_id, max_gen_len=128, stop_tokens_ids=terminators):\n",
    "        print(f\"{word}\", end='', flush=True)\n",
    "        output_text.append(word)\n",
    "        total_tokens_count += n_tokens\n",
    "    delta_time = time.time() - start_time\n",
    "    output_text = \"\".join(output_text)\n",
    "    print()\n",
    "else:  \n",
    "    start_time = time.time()\n",
    "    outputs, total_tokens_count = generate_text(model, tokenizer, input_ids, max_gen_len=128, stop_tokens_ids=terminators)\n",
    "    delta_time = time.time() - start_time\n",
    "    print([text+output for text, output in zip(texts, outputs)])\n",
    "print(f\"Generation took {delta_time} seconds, {total_tokens_count/delta_time} tokens/s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbb2b0e-8ece-46d5-8360-52d74e83e0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29154a8f-80f5-4e2f-844e-a27a4a6c49fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
